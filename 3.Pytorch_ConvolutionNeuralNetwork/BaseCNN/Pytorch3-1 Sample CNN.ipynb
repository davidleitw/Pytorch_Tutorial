{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a465571cd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "Epochs = 3\n",
    "BatchSize = 50\n",
    "LearningRate = 0.02\n",
    "DOWNLOAD_MNIST = False   # set to False if you have downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Mnist DataSet\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "                                        root='D:\\Python_MechineLearning\\pytorch\\mnist',\n",
    "                                        train=True,\n",
    "                                        transform=torchvision.transforms.ToTensor(),\n",
    "                                        download=DOWNLOAD_MNIST,)\n",
    "print(type(train_data))\n",
    "print(type(train_data.train_data))\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root='D:\\Python_MechineLearning\\pytorch\\mnist',train=False)\n",
    "\n",
    "print(type(test_data))\n",
    "print(type(test_data.test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape = torch.Size([60000, 28, 28])\n",
      "Train label shape  = torch.Size([60000])\n",
      "\n",
      "\n",
      "Test data shape = torch.Size([10000, 28, 28])\n",
      "Test data label shape = torch.Size([10000])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train data shape = {s}'.format(s=train_data.train_data.shape))   # 60000 picture\n",
    "print('Train label shape  = {s}\\n\\n'.format(s=train_data.train_labels.shape)) # 60000 labels\n",
    "\n",
    "print('Test data shape = {s}'.format(s=test_data.test_data.shape))\n",
    "print('Test data label shape = {s}\\n'.format(s=test_data.test_labels.shape))\n",
    "\n",
    "plt.imshow(train_data.train_data[1].numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "# Batch train, Input shape = (50,1,28,28) \n",
    "DataLoader = torch.utils.data.DataLoader(dataset=train_data,shuffle=True,batch_size=BatchSize)\n",
    "print(type(DataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detail about Conv2d in https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    # Class_Num mean 0~9\n",
    "    def __init__(self, Class_Num=10): \n",
    "        super(CNN,self).__init__()\n",
    "        # nn.Conv2d(in, out, kernel_size, stride, padding)\n",
    "        # out = filters number\n",
    "        # in  = input height\n",
    "        # kernel_size = n -> n*n kernel\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.n1 = nn.Linear(256, 60)\n",
    "        self.n2 = nn.Linear(60, 84)\n",
    "        self.n3 = nn.Linear(84, Class_Num)\n",
    "    def forward(self, x)-> torch.tensor:\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.n1(x))\n",
    "        x = F.relu(self.n2(x))\n",
    "        x1 = self.n3(x)\n",
    "        return x1\n",
    "    # View every layer shape\n",
    "    def TestFunction(self, x)-> torch.tensor:\n",
    "        print('\\n\\n==== In the test function: ====')\n",
    "        print('Input data size = {}'.format(x.shape))\n",
    "        out = self.conv1(x)\n",
    "        print('After Conv1:',out.shape)\n",
    "        out = F.max_pool2d(F.relu(out), (2, 2))\n",
    "        print('After Maxpooling 1 :',out.shape)\n",
    "        out = self.conv2(out)\n",
    "        print('After Conv2 : ',out.shape)\n",
    "        out = F.max_pool2d(F.relu(out), (2, 2))\n",
    "        print('After Maxpooling 2 :',out.shape)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        print('After Fitting',out.shape)\n",
    "        out = F.relu(self.n1(out))\n",
    "        print('After Linear N1 :',out.shape)\n",
    "        out = F.relu(self.n2(out))\n",
    "        print('After Linear N2 :',out.shape)\n",
    "        out = self.n3(out)\n",
    "        print('After Linear N3 :',out.shape)\n",
    "        print('==== End of the test function ====\\n\\n')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (n1): Linear(in_features=256, out_features=60, bias=True)\n",
      "  (n2): Linear(in_features=60, out_features=84, bias=True)\n",
      "  (n3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "conv1.weight : torch.Size([16, 1, 5, 5])\n",
      "conv1.bias : torch.Size([16])\n",
      "conv2.weight : torch.Size([16, 16, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "n1.weight : torch.Size([60, 256])\n",
      "n1.bias : torch.Size([60])\n",
      "n2.weight : torch.Size([84, 60])\n",
      "n2.bias : torch.Size([84])\n",
      "n3.weight : torch.Size([10, 84])\n",
      "n3.bias : torch.Size([10])\n",
      "\n",
      "\n",
      "==== In the test function: ====\n",
      "Input data size = torch.Size([50, 1, 28, 28])\n",
      "After Conv1: torch.Size([50, 16, 24, 24])\n",
      "After Maxpooling 1 : torch.Size([50, 16, 12, 12])\n",
      "After Conv2 :  torch.Size([50, 16, 8, 8])\n",
      "After Maxpooling 2 : torch.Size([50, 16, 4, 4])\n",
      "After Fitting torch.Size([50, 256])\n",
      "After Linear N1 : torch.Size([50, 60])\n",
      "After Linear N2 : torch.Size([50, 84])\n",
      "After Linear N3 : torch.Size([50, 10])\n",
      "==== End of the test function ====\n",
      "\n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 10])\n",
      "tensor([ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "         0.0516, -0.0448], grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "         0.0516, -0.0448], grad_fn=<SelectBackward>) \n",
      "\n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 10])\n",
      "tensor([[ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448],\n",
      "        [ 0.0752, -0.0528, -0.0919, -0.0041, -0.0876,  0.0317, -0.0051,  0.1183,\n",
      "          0.0516, -0.0448]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "Cnn = CNN()\n",
    "print(Cnn)\n",
    "for name, parameters in Cnn.named_parameters():\n",
    "    print(name,':',parameters.shape)\n",
    "\n",
    "testdata = torch.ones(50, 1, 28, 28)\n",
    "\n",
    "# Use the TestFunction to watch every layer shape\n",
    "test = Cnn.TestFunction(testdata)\n",
    "print(type(test))\n",
    "print(test.shape)\n",
    "print(test[0])\n",
    "print(test[1],'\\n\\n')\n",
    "\n",
    "test2 = Cnn(testdata)\n",
    "print(type(test2))\n",
    "print(test2.shape)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and loss function\n",
    "Optimizer = torch.optim.Adam(Cnn.parameters(),lr=LearningRate)\n",
    "Loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Epoch 1, Step 1 : Loss = 2.3041305541992188\n",
      "In Epoch 1, Step 50 : Loss = 0.8391541838645935\n",
      "In Epoch 1, Step 100 : Loss = 0.5008198022842407\n",
      "In Epoch 1, Step 150 : Loss = 0.2859257757663727\n",
      "In Epoch 1, Step 200 : Loss = 0.2903510332107544\n",
      "In Epoch 1, Step 250 : Loss = 0.2500843405723572\n",
      "In Epoch 1, Step 300 : Loss = 0.5445688366889954\n",
      "In Epoch 1, Step 350 : Loss = 0.02414477802813053\n",
      "In Epoch 1, Step 400 : Loss = 0.3303970992565155\n",
      "In Epoch 1, Step 450 : Loss = 0.3636881709098816\n",
      "In Epoch 1, Step 500 : Loss = 0.06154414266347885\n",
      "In Epoch 1, Step 550 : Loss = 0.2082306444644928\n",
      "In Epoch 1, Step 600 : Loss = 0.37433791160583496\n",
      "In Epoch 1, Step 650 : Loss = 0.09910938143730164\n",
      "In Epoch 1, Step 700 : Loss = 0.22424747049808502\n",
      "In Epoch 1, Step 750 : Loss = 0.2493910938501358\n",
      "In Epoch 1, Step 800 : Loss = 0.09095758199691772\n",
      "In Epoch 1, Step 850 : Loss = 0.14179186522960663\n",
      "In Epoch 1, Step 900 : Loss = 0.192717507481575\n",
      "In Epoch 1, Step 950 : Loss = 0.1894713044166565\n",
      "In Epoch 1, Step 1000 : Loss = 0.2654350996017456\n",
      "In Epoch 1, Step 1050 : Loss = 0.309887170791626\n",
      "In Epoch 1, Step 1100 : Loss = 0.15115004777908325\n",
      "In Epoch 1, Step 1150 : Loss = 0.20268405973911285\n",
      "In Epoch 1, Step 1200 : Loss = 0.2401876002550125\n",
      "In Epoch 2, Step 1 : Loss = 0.11523379385471344\n",
      "In Epoch 2, Step 50 : Loss = 0.18117068707942963\n",
      "In Epoch 2, Step 100 : Loss = 0.26309695839881897\n",
      "In Epoch 2, Step 150 : Loss = 0.06306401640176773\n",
      "In Epoch 2, Step 200 : Loss = 0.14031705260276794\n",
      "In Epoch 2, Step 250 : Loss = 0.00404716469347477\n",
      "In Epoch 2, Step 300 : Loss = 0.1014460101723671\n",
      "In Epoch 2, Step 350 : Loss = 0.11318759620189667\n",
      "In Epoch 2, Step 400 : Loss = 0.23700207471847534\n",
      "In Epoch 2, Step 450 : Loss = 0.18353968858718872\n",
      "In Epoch 2, Step 500 : Loss = 0.09994717687368393\n",
      "In Epoch 2, Step 550 : Loss = 0.39332932233810425\n",
      "In Epoch 2, Step 600 : Loss = 0.3159218430519104\n",
      "In Epoch 2, Step 650 : Loss = 0.03696064651012421\n",
      "In Epoch 2, Step 700 : Loss = 0.16349923610687256\n",
      "In Epoch 2, Step 750 : Loss = 0.03636468946933746\n",
      "In Epoch 2, Step 800 : Loss = 0.10548728704452515\n",
      "In Epoch 2, Step 850 : Loss = 0.0754813551902771\n",
      "In Epoch 2, Step 900 : Loss = 0.012115230783820152\n",
      "In Epoch 2, Step 950 : Loss = 0.16795049607753754\n",
      "In Epoch 2, Step 1000 : Loss = 0.34003859758377075\n",
      "In Epoch 2, Step 1050 : Loss = 0.29016417264938354\n",
      "In Epoch 2, Step 1100 : Loss = 0.2573934495449066\n",
      "In Epoch 2, Step 1150 : Loss = 0.15434767305850983\n",
      "In Epoch 2, Step 1200 : Loss = 0.28066617250442505\n",
      "In Epoch 3, Step 1 : Loss = 0.1600310355424881\n",
      "In Epoch 3, Step 50 : Loss = 0.3409767150878906\n",
      "In Epoch 3, Step 100 : Loss = 0.29060453176498413\n",
      "In Epoch 3, Step 150 : Loss = 0.2034182995557785\n",
      "In Epoch 3, Step 200 : Loss = 0.11666298657655716\n",
      "In Epoch 3, Step 250 : Loss = 0.2236873209476471\n",
      "In Epoch 3, Step 300 : Loss = 0.27885425090789795\n",
      "In Epoch 3, Step 350 : Loss = 0.12180330604314804\n",
      "In Epoch 3, Step 400 : Loss = 0.18192064762115479\n",
      "In Epoch 3, Step 450 : Loss = 0.13583846390247345\n",
      "In Epoch 3, Step 500 : Loss = 0.18159830570220947\n",
      "In Epoch 3, Step 550 : Loss = 0.051574088633060455\n",
      "In Epoch 3, Step 600 : Loss = 0.07228939980268478\n",
      "In Epoch 3, Step 650 : Loss = 0.05156021937727928\n",
      "In Epoch 3, Step 700 : Loss = 0.29451170563697815\n",
      "In Epoch 3, Step 750 : Loss = 0.08614549785852432\n",
      "In Epoch 3, Step 800 : Loss = 0.11240280419588089\n",
      "In Epoch 3, Step 850 : Loss = 0.1795322746038437\n",
      "In Epoch 3, Step 900 : Loss = 0.05343903973698616\n",
      "In Epoch 3, Step 950 : Loss = 0.1708635687828064\n",
      "In Epoch 3, Step 1000 : Loss = 0.1361583173274994\n",
      "In Epoch 3, Step 1050 : Loss = 0.3324631452560425\n",
      "In Epoch 3, Step 1100 : Loss = 0.25349515676498413\n",
      "In Epoch 3, Step 1150 : Loss = 0.25408628582954407\n",
      "In Epoch 3, Step 1200 : Loss = 0.18482351303100586\n",
      "Result, Loss = 0.18482351303100586\n",
      "Total time = 238.9696056842804\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "start = time.time()\n",
    "for epoch in range(Epochs):\n",
    "    for step, (x, y) in enumerate(DataLoader):\n",
    "        Output = Cnn(x)\n",
    "        #print(Output.shape)\n",
    "        LossValue = Loss_func(Output, y)\n",
    "        \n",
    "        Optimizer.zero_grad()\n",
    "        LossValue.backward()\n",
    "        Optimizer.step()\n",
    "        \n",
    "        if (step+1)%50==0 or step==0:\n",
    "            print('In Epoch {e}, Step {s} : Loss = {l}'.format(e=epoch+1, s=step+1, l=LossValue.item()))\n",
    "end = time.time()\n",
    "print('Result, Loss = {l}\\nTotal time = {t}'.format(l=LossValue.item(), t=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Test data reshape\n",
    "print(type(test_data))\n",
    "\n",
    "print(test_data.test_data.shape)\n",
    "#test_data.test_data = torch.squeeze(test_data.test_data, 0)\n",
    "test_data.test_data = torch.unsqueeze(test_data.test_data, 1)\n",
    "print(test_data.test_data.shape)\n",
    "print(test_data.test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape =  torch.Size([10000, 1, 28, 28])\n",
      "Output shape =  torch.Size([10000, 10])\n",
      "torch.Size([10000])\n",
      "torch.Size([10000])\n",
      "Total accuracy = 91.42%\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "test_data.test_data = test_data.test_data.float()\n",
    "print('test data shape = ',test_data.test_data.shape)\n",
    "Result = Cnn(test_data.test_data)\n",
    "print('Output shape = ', Result.shape)\n",
    "\n",
    "# How to use torch.max please see https://github.com/davidleitw/Pytorch_Learn/blob/master/4.Pytorch_CommonFunc/torch.max.ipynb\n",
    "Predict = torch.max(Result, 1)[1]\n",
    "print(Predict.shape)\n",
    "print(test_data.test_labels.shape)\n",
    "print('Total accuracy = {}%'.format(((Predict==test_data.test_labels).sum().item())/100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save the madel\n",
    "torch.save(Cnn,'SampleCnn.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
